\chapter{Lineare Abbildungen}
Lineare Abbildungen sind Strukturerhaltende Abbildungen zwischen Vektorräumen, sie werden deshalb auch Vektorraumhomomorphismen genannt.
\begin{definition}{Lineare Abbildungen}
	Seien $V$ und $W$ Vektorräume über dem selben Körper $K$. Eine Abbildung $f:V\rightarrow W$ heißt \emph{linear}, falls
	\begin{description}
	  \item[L 1] $\forall u,v \in V : f(u+v)= f(u)+f(v)$ (Additivität)
	  \item[L 2] $\forall v\in V, \lambda \in K : f(\lambda v) = \lambda * f(v)$ (Homogenität)
	\end{description}
\end{definition}


\paragraph{Bemerkung:}
\textbf{L 1} ist dazu äquivalent, dass $f$ ein Gruppenhomomorphismus zwischen den abel'schen Gruppen $(V,+)$ und $(W,+)$ ist.

\paragraph{Beispiele:}
\begin{itemize}
  \item Für alle $\lambda \in K$ ist $f:V\rightarrow V, v\mapsto \lambda v$ eine Lineare Abbildung
  \item Insbesondere sind die identische Abbildung
  \begin{equation*}
    \mathrm{id}_V:V\rightarrow V, v\mapsto v
  \end{equation*}
  und die Nullabbildung
  \begin{equation*}
    \mathrm{n}_V:V\rightarrow V, v\mapsto 0
  \end{equation*}
  linere Abbildungen.

  \item $f:\R\rightarrow\R, x\mapsto x^2$ ist \emph{nicht} linear, denn
  \begin{equation*}
    4=f(2)=f(1+1)\neq f(1)+f(1) = 2
  \end{equation*}
\end{itemize}

\section{Matrizen}
Allgemein lassen sich lineare Abbildungen durch sog. \emph{Matrizen} darstellen.

Sei $A$ eine $m\times n$-Matrix, d.h. ein rechteckiges Zahlenschema mit $m$ Zeilen und $n$ Spalten:
\newcommand{\ma}[1]{\ensuremath a_{#1}}
\begin{equation*}
  A=
  \matrix{
  \ma{11} & \ma{12} & \cdots & \ma{1n}\\
  \ma{21} & \ma{22} & \cdots & \ma{2n}\\
  \vdots & \vdots & \ddots & \vdots\\
  \ma{m1} & \ma{m2} & \cdots & \ma{mn}\\
  }
  = ((a_{ij}))_{\substack{1\leq i\leq m\\1\leq j\leq n}}
\end{equation*}
Dann ist durch
\begin{equation*}
  f(x_1,x_2,\ldots,x_n)\coloneqq A*\matrix{x_1\\x_2\\\vdots\\x_n}
  =\matrix{
  \ma{11}x_1+\ma{12}x_2+\ldots+\ma{1n}x_n\\
  \ma{21}x_1+\ma{22}x_2+\ldots+\ma{2n}x_n\\
  \vdots\\
  \ma{m1}x_1+\ma{m2}x_2+\ldots+\ma{mn}x_n\\
  }
\end{equation*}
eine lineare Abbildung $f:K^n\rightarrow K^m$ gegeben.

\bemerkung
Jede lineare Abbildung $f:K^n\rightarrow K^m$ lässt sich auf diese Weise mit einer $m\times n$-Matrix mit Einträgen in $K$ darstellen.

\begin{satz}{}
  Sei $B$ eine Basis des $K$-Vektorraums $V$ und sei $W$ ein weiterer $K$-Vektorraum.
  Sei eine Abbildung $g:B\rightarrow W$ gegeben. Dann gibt es genau eine lineare Abbildung $f:V\rightarrow W$, die $g$ in dem Sinne fortsetzt, dass $f(b)=g(b) \quad\forall b\in B$ gilt.
\end{satz}


\beweis
Sei $v$ ein beliebiger Vektor aus $V$. Dann kann man diesen durch Linearkombination der Basisvektoren $b_1,\ldots,b_k \in B$ darstellen:
\begin{equation*}
  v=\lambda_1b_1+\ldots+\lambda_kb_k
\end{equation*}
Angenommen, $f$ sei eine lineare Abbildung $f:V\rightarrow W$, dann gilt:
\begin{align*}
  f(v) &= f(\lambda_1b_1+\ldots+\lambda_kb_k)\\
  &= f(\lambda_1b_1)+\ldots+f(\lambda_kb_k)\\
  &= \lambda_1f(b_1)+\ldots+\lambda_kf(b_k)\\
  &= \lambda_1g(b_1)+\ldots+\lambda_kg(b_k)
\end{align*}
Damit ist der Wert von $f(v)$ bestimmt, dies zeigt die Eindeutigkeit.
\par\medskip
Um die Existenz einer solchen Abbildung zu zeigen, bemerken wir, dass die Linearkombination von $v$ mit $B$ eindeutig ist, da $B$ eine Basis von $V$ ist.
Dies zeigt, dass $f:V\rightarrow W$ wohldefiniert ist, wenn wir die Formel von $f(v)$ als Definition von $f$ verwenden.
Es ist noch zu zeigen, dass die so definierte Abbildung linear ist.
\par\smallskip
Seien zwei Vektoren $u,v\in V$ gegeben.

Dann gibt es $\lambda_1,\ldots,\lambda_k$, $\mu_1,\ldots,\mu_l$, $v_1,\ldots,v_k$ und $w_1,\ldots,w_l$ so dass gilt:
\begin{equation*}
  u=\lambda_1v_1 + \ldots + \lambda_kv_k
\end{equation*}
\begin{equation*}
  v=\mu_1v_1 + \ldots + \mu_lw_l
\end{equation*}
Insbesondere gibt es Vektoren $b_1,\ldots,b_m \in B$ und Skalare $\alpha_1,\ldots,\alpha_m \in K$, $\beta_1,\ldots,\beta_m \in K$ so dass
\begin{equation*}
  u=\alpha_1b_1 + \ldots + \alpha_mb_m
\end{equation*}
\begin{equation*}
  v=\beta_1b_1 + \ldots + \beta_mb_m
\end{equation*}

Dann folgt mit unserer Definition:
\begin{align*}
  f(u+v) &= f(\alpha_1b_1 + \ldots + \alpha_mb_m + \beta_1b_1 + \ldots + \beta_mb_m)\\
  &= f((\alpha_1\beta_1)b_1)+\ldots+f((\alpha_m\beta_m)b_m)\\
  &= (\alpha_1\beta_1)g(b_1)+\ldots+(\alpha_m\beta_m)g(b_m)\\
  &= f(u)+f(v)
\end{align*}
Damit ist die Additivität gezeigt.

Um die Homogenität zu zeigen, bemerken wir, falls $v=\lambda_1b_1+\ldots+\lambda_kb_k$ und $\mu\in K$:
\begin{equation*}
  f(\mu*v)=f(\mu(\lambda_1b_1+\ldots+\lambda_kb_k))=\mu*f(v)
\end{equation*}

\section{Darstellende Matrix}
Wenn wir nun annehmen, dass $V$ und $W$ endlich dimensional sind, d.h es gibt endlich viele Basisvektoren $v_1,\ldots,v_n$ von $V$ und $w_1,\ldots,w_m$ von $W$. Dann genügt es, dass man zu jedem Basisvektor $v_j$ die eindeutig bestimmte Darstellung des Vektors $f(v_j)$ bezüglich der Basis $\simpleset{w_1,\ldots,w_m}$ kennt.

Seien also durch
\begin{equation*}
  f(v_j) = \ma{1j}w_1+\ldots+\ma{mj}w_m
\end{equation*}
die Einträge einer Matrix mit Koeffizietn $a_{ij} \in K$ gegeben:
\begin{equation*}
  A=\matrix{
  \ma{11}x_1+\ma{12}x_2+\ldots+\ma{1n}x_n\\
  \ma{21}x_1+\ma{22}x_2+\ldots+\ma{2n}x_n\\
  \vdots\\
  \ma{m1}x_1+\ma{m2}x_2+\ldots+\ma{mn}x_n\\
  }
\end{equation*}
Dann ist in der Matrix die gesamte Information über die lineare Abbildung $f$ enthalten.

Umgekehrt ist durch eine beliebige $m\times n$-Matrix (m Zeilen, n Spalten) mit Einträgen aus $K$ eine lineare Abbildung $V\rightarrow W$ bezüglich der Basen $\simpleset{v_1,\ldots,v_n}$ und $\simpleset{w_1,\ldots,w_m}$ gegeben.

Die Matrix $A$ heißt \emph{darstellende Matrix} der linearen Abbildung bezüglich der Basen $v_1,\ldots,v_n$ und $w_1,\ldots,w_m$.

\begin{definition}{Darstellende Matrix}
	Seien $m,n\in\N_0$. Die Menge der $m\times n$-Matrizen mit Einträgen aus $K$ wird mit $\mathrm{M}(m,n,K)$ bezeichnet. Seien $v_1,\ldots,v_n$ und $w_1,\ldots,w_m$ jeweils eine Basis des $K$-Vektorraums $V$ bzw. $W$. Und sei $f:V\rightarrow W$ eine lineare Abbildung. Dann nennt man
	\begin{equation*}
	  A=((a_{ij}))\in \mathrm{M}(m,n,K)
	\end{equation*}
	die \emph{darstellende Matrix} von $f$ bezüglich den Basen $v_1,\ldots,v_n$ und $w_1,\ldots,w_m$ von $V$ bzw. $W$, falls
	\begin{equation*}
	  f(v_j) = \ma{1j}w_1+\ldots+\ma{mj}w_m \quad\forall j\in\simpleset{1,\ldots,n}
	\end{equation*}
\end{definition}

\paragraph{Merkregel}
Die Spalten der darstellenden Matrix sind die Bilder der Basisvektoren.
\par\bigskip


Lineare Abbildungen sind wegen der Additivität Insbesondere Gruppenhomomorphismen bezüglich der Addition. Analog wie für Gruppenhomomorphismen gilt:

\begin{satz}{}
  Bild und Kern einer linearen Abbildung $f:V\rightarrow W$ sind jeweils Untervektorräume von $V$ bzw. $W$.
\end{satz}

\beweis
\begin{itemize}
	\item $\mathrm{Bild}(f)$ ist ein Untervektorraum von $W$:

	Wegen $f(0)\in\mathrm{Bild}(f)$ ist $\mathrm{Bild}(f)$ nicht leer.

	Seien außerdem $f(u),f(v)\in\mathrm{Bild}(f)$, dann gilt:
	\begin{align*}
		f(u)+f(v)=f(u+v)\in\mathrm{Bild}(f)\\
		\intertext{und ebenso}
		\lambda f(v)=f(\lambda*v)\in\mathrm{Bild}(f) \quad \forall\lambda\in K
	\end{align*}

	\item $\mathrm{Kern}(f)$ ist ein Untervektorraum von $V$:

	Es gilt für jede lineare Abbildung, dass das neutrale Element eines Vektorraums auf das neutrale Element des Zielvektorraums abgebildet wird, d.h. $f(0)=0$. Also ist $\mathrm{Kern}(f)$ nicht leer.

	Seien $u,v\in \mathrm{Kern}(f)$, dann folgt:
	\begin{align*}
		f(u+v)=f(u)+f(v)=0+0=0 \in\mathrm{Kern}(f)\\
		\intertext{und ebenso}
		f(\lambda *v)=\lambda f(v)=\lambda*0=0\in\mathrm{Kern}(f) \quad\forall \lambda\in K
	\end{align*}
\end{itemize}


\begin{definition}{}
  Eine lineare Abbildung $f: V\rightarrow W$ heißt
  \begin{equation*}
    \text{Vektorraum-}
    \begin{cases}
      \text{Monomorphismus, falls $f$ injektiv ist}\\
      \text{Epimorphismus, falls $f$ surjektiv ist}\\
      \text{Isomorphismus, falls $f$ bijektiv ist}\\
			\text{Endomorphismus, falls $W=V$}\\
			\text{Automorphismus, falls $f$ ein bijektiver Endomorphismus ist}
    \end{cases}
  \end{equation*}
\end{definition}
\paragraph{Bemerkung:}
\begin{itemize}
	\item Die Automorphismen $\mathrm{Aut}(V)$ eines Vektorraums $V$ bilden eine Gruppe mit der Verkettung als Verknüpfung.
	\item Die Menge der Endo- bzw. Automorphismen wird mit $\mathrm{End}(V)$ bzw. $\mathrm{Aut}(V)$ bezeichnet.
	\item Die Menge der linearen Abbildungen $V\rightarrow W$ mit $\mathrm{Hom}(V,W)$.
\end{itemize}


\begin{definition}{Rang einer Abbildung}
  Die Dimension des Bildes einer linearen Abbildung $f$ heißt auch \emph{Rang} von $f$ (engl. rank).
  \begin{equation*}
    \rank{f} \coloneqq \dim{\ker f}
  \end{equation*}
\end{definition}

\begin{satz}{Dimensionsformel für lineare Abbildungen}
  Für lineare Abbildungen $f:V\rightarrow W$ gilt, falls $V$ endlich dimensional ist, die \emph{Dimensionsformel für lineare Abbildungen}:
  \begin{align*}
    \dim{V}&=\rank{f}+\dim{\ker f}\\
    &=\dim{\ker f}+\dim{\ker f}
  \end{align*}
\end{satz}

\begin{lemma}{}
  Eine lineare Abbildung $f:V\rightarrow W$ ist genau dann injektiv, wenn ihr Kern trivial ist.
\end{lemma}
